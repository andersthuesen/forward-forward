{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.optim import SGD\n",
    "\n",
    "\n",
    "from typing import List, Union\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = MNIST(root=\"./data\", download=True, transform=T.Compose([T.ToTensor(), T.Normalize(0.1307, 0.3014)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = DataLoader(mnist_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFLayer(nn.Module):\n",
    "  # What should the learning objective be?\n",
    "  class GoodnessMeasure(Enum):\n",
    "    SUM_OF_SQUARED_ACTIVITIES = 1\n",
    "    SUM_OF_ACTIVITIES = 2\n",
    "\n",
    "  class MaxObjective(Enum):\n",
    "    LIKELIHOOD = 1\n",
    "    LOG_LIKELIHOOD = 2\n",
    "    GOODNESS = 3\n",
    "    NEGATIVE_GOODNESS = 4\n",
    "\n",
    "  def __init__(self, in_features, out_features, threshold=2, \n",
    "              good_measure=GoodnessMeasure.SUM_OF_SQUARED_ACTIVITIES, max_obj=MaxObjective.LOG_LIKELIHOOD, lr=1e-3):\n",
    "\n",
    "    super(FFLayer, self).__init__()\n",
    "    self.linear = nn.Linear(in_features, out_features)\n",
    "    self.activation = nn.ReLU(inplace=True)\n",
    "    self.opt = SGD(self.linear.parameters(), lr=lr)\n",
    "\n",
    "    self.good_measure = good_measure\n",
    "    self.threshold = threshold\n",
    "    self.max_obj = max_obj\n",
    "\n",
    "  def prob_positive(self, x):\n",
    "    return F.sigmoid(self.goodness(x) - self.threshold)\n",
    "\n",
    "  def goodness(self, x):\n",
    "    a = self.forward(x)\n",
    "    if self.good_measure == self.GoodnessMeasure.SUM_OF_SQUARED_ACTIVITIES:\n",
    "      return (a**2).sum()\n",
    "    elif self.good_measure == self.GoodnessMeasure.SUM_OF_ACTIVITIES:\n",
    "      return a.sum()\n",
    "\n",
    "  def train(self, x):\n",
    "    self.opt.zero_grad()\n",
    "    loss = None\n",
    "    if self.max_obj == self.MaxObjective.LIKELIHOOD:\n",
    "      loss = -self.prob_positive(x)\n",
    "    elif self.max_obj == self.MaxObjective.LOG_LIKELIHOOD:\n",
    "      loss = -torch.log(self.prob_positive(x))\n",
    "    elif self.max_obj == self.MaxObjective.GOODNESS:\n",
    "      loss = -self.goodness(x)\n",
    "    elif self.max_obj == self.MaxObjective.NEGATIVE_GOODNESS:\n",
    "      loss = self.goodness(x)\n",
    "    loss.backward()\n",
    "    self.opt.step()\n",
    "\n",
    "  def forward(self, x):\n",
    "    n = F.normalize(x, 2)\n",
    "    h = self.linear(n)\n",
    "    a = self.activation(h)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentFFModel(nn.Module):\n",
    "  def __init__(self, input_size: int, layer_sizes: List[layer_size], \n",
    "                rollouts=8, lr=1e-3, max_obj=FFLayer.MaxObjective.NEGATIVE_GOODNESS):\n",
    "                \n",
    "    super(RecurrentFFModel, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.rollouts = rollouts\n",
    "    self.lr = lr\n",
    "\n",
    "    self.max_obj = max_obj\n",
    "\n",
    "    \"\"\"\n",
    "    Each layer depends on layers above and below, except top layer.\n",
    "                   ___     ___           <--- Top layer\n",
    "               ___/   \\___/   \\___       <--- Middle layer (could be many)\n",
    "           ___/   \\___/   \\___/   \\___   <--- Bottom layer\n",
    "          /       /       /       /\n",
    "     frame   frame   frame   frame\n",
    "\n",
    "    \"\"\"\n",
    "    self.layers = []\n",
    "    up_size = input_size\n",
    "    for out_size, down_size in zip(layer_sizes, layer_sizes[1:]):\n",
    "      layer = self.make_layer(up_size, down_size, out_size)\n",
    "      self.layers.append(layer)\n",
    "      up_size = out_size\n",
    "    # Top layer only gets input from layer below, hence down_size=0.\n",
    "    top_layer = self.make_layer(up_size=layer_sizes[-2], down_size=0, out_size=layer_sizes[-1])\n",
    "    self.layers.append(top_layer)\n",
    "\n",
    "  def make_layer(self, up_size, down_size, out_size):\n",
    "    return FFLayer(up_size + down_size, out_size, lr=self.lr, max_obj=self.max_obj)\n",
    "\n",
    "  def train(self, x):\n",
    "    pass\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Initialize layer activities\n",
    "    activity = [x] + [torch.zeros(x.shape[0], l.out_features) for l in self.layers] + [torch.zeros(x.shape[0], 0)]\n",
    " \n",
    "    # Rollout time\n",
    "    for rollout in range(self.rollouts):\n",
    "      new_activity = activity.copy()\n",
    "      for i, layer in enumerate(self.layers): # This could be done in parallel\n",
    "        j = i + 1 # Activity index\n",
    "\n",
    "        # Concatenative activities from layers below and above\n",
    "        # and prevent propagation of gradients using .detach()\n",
    "        layer_input = torch.cat((activity[j-1], activity[j+1]), dim=1).detach()\n",
    "        y = layer(layer_input)\n",
    "\n",
    "        new_activity[j] = y\n",
    "\n",
    "      activity = new_activity # Switch activities\n",
    "\n",
    "    return activity[1:-1] # Only return hidden activities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentFFModel(input_size=28*28, layer_sizes=[400, 200, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.1034e-05, grad_fn=<MeanBackward0>) tensor(0.0184, grad_fn=<StdBackward0>)\n",
      "tensor(-0.0008, grad_fn=<MeanBackward0>) tensor(0.0186, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight.mean(), model.layers[0].weight.std())\n",
    "print(model.layers[0].bias.mean(), model.layers[0].bias.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb3763298e24337910bba7503bb1055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in tqdm(mnist_data):\n",
    "  image = image.flatten(start_dim=1) # Flatten image\n",
    "  model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3312e-05, grad_fn=<MeanBackward0>) tensor(0.0184, grad_fn=<StdBackward0>)\n",
      "tensor(-0.0182, grad_fn=<MeanBackward0>) tensor(0.0060, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight.mean(), model.layers[0].weight.std())\n",
    "print(model.layers[0].bias.mean(), model.layers[0].bias.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of dividing the above into multiple layers, we could have one big matrix of connection weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
