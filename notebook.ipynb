{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import List, Union\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset = MNIST(root=\"./data\", train=True, download=True, transform=T.Compose([T.ToTensor(), T.Normalize(0.1307, 0.3014)]))\n",
    "mnist_test_dataset = MNIST(root=\"./data\", train=False, download=True, transform=T.Compose([T.ToTensor(), T.Normalize(0.1307, 0.3014)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_data = DataLoader(mnist_train_dataset, batch_size=16)\n",
    "mnist_test_data = DataLoader(mnist_test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFLayer(nn.Module):\n",
    "  class GoodnessMeasure(Enum):\n",
    "    SUM_OF_SQUARED_ACTIVITIES = 1\n",
    "    SUM_OF_ACTIVITIES = 2\n",
    "\n",
    "  class MaxObjective(Enum):\n",
    "    LIKELIHOOD = 1\n",
    "    LOG_LIKELIHOOD = 2\n",
    "    GOODNESS = 3\n",
    "    NEGATIVE_GOODNESS = 4\n",
    "\n",
    "  def __init__(self, in_features, out_features, threshold=2, \n",
    "              good_measure=GoodnessMeasure.SUM_OF_SQUARED_ACTIVITIES, max_obj=MaxObjective.LOG_LIKELIHOOD, lr=1e-3):\n",
    "\n",
    "    super(FFLayer, self).__init__()\n",
    "    self.in_features = in_features\n",
    "    self.out_features = out_features\n",
    "    self.linear = nn.Linear(in_features, out_features)\n",
    "    self.activation = nn.ReLU(inplace=True)\n",
    "    self.opt = SGD(self.linear.parameters(), lr=lr)\n",
    "\n",
    "    self.good_measure = good_measure\n",
    "    self.threshold = threshold\n",
    "    self.max_obj = max_obj\n",
    "\n",
    "  def prob_positive(self, x):\n",
    "    goodness, activity = self.goodness(x)\n",
    "    return torch.sigmoid(goodness - self.threshold), activity\n",
    "\n",
    "  def goodness(self, x):\n",
    "    activity = self.forward(x)\n",
    "    if self.good_measure == self.GoodnessMeasure.SUM_OF_SQUARED_ACTIVITIES:\n",
    "      goodness = (activity**2).sum()\n",
    "    elif self.good_measure == self.GoodnessMeasure.SUM_OF_ACTIVITIES:\n",
    "      goodness = activity.sum()\n",
    "    return goodness, activity\n",
    "\n",
    "  def train(self, x, negative=False):\n",
    "    sign = -1 if negative else 1\n",
    "    loss = None\n",
    "    activity = None\n",
    "\n",
    "    if self.max_obj == self.MaxObjective.LIKELIHOOD:\n",
    "      prob_pos, activity = self.prob_positive(x)\n",
    "      loss = sign * -prob_pos\n",
    "  \n",
    "    elif self.max_obj == self.MaxObjective.LOG_LIKELIHOOD:\n",
    "      prob_pos, activity = self.prob_positive(x)\n",
    "      loss = sign * -torch.log(prob_pos)\n",
    "\n",
    "    elif self.max_obj == self.MaxObjective.GOODNESS:\n",
    "      goodness, activity = self.goodness(x)\n",
    "      loss = sign * -goodness\n",
    "\n",
    "    elif self.max_obj == self.MaxObjective.NEGATIVE_GOODNESS:\n",
    "      goodness, activity = self.goodness(x)\n",
    "      loss = sign * goodness\n",
    "\n",
    "    self.opt.zero_grad()\n",
    "    loss.backward()\n",
    "    self.opt.step()\n",
    "    return activity\n",
    "\n",
    "  def train_pos(self, x):\n",
    "    return self.train(x, negative=False)\n",
    "\n",
    "  def train_neg(self, x):\n",
    "    return self.train(x, negative=True)\n",
    "\n",
    "  def forward(self, x):\n",
    "    n = F.normalize(x, 2) \n",
    "    h = self.linear(n)\n",
    "    a = self.activation(h)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentFFModel(nn.Module):\n",
    "  def __init__(self, input_size: int, layer_sizes: List[int], \n",
    "                rollouts=8, lr=1e-3, max_obj=FFLayer.MaxObjective.LOG_LIKELIHOOD):\n",
    "                \n",
    "    super(RecurrentFFModel, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.rollouts = rollouts\n",
    "    self.lr = lr\n",
    "\n",
    "    self.max_obj = max_obj\n",
    "\n",
    "    \"\"\"\n",
    "    Each layer depends on layers above and below, except top layer.\n",
    "                   ___     ___           <--- Top layer\n",
    "               ___/   \\___/   \\___       <--- Middle layer (could be many)\n",
    "           ___/   \\___/   \\___/   \\___   <--- Bottom layer\n",
    "          /       /       /       /\n",
    "     frame   frame   frame   frame\n",
    "\n",
    "    \"\"\"\n",
    "    self.layers = []\n",
    "    up_size = input_size\n",
    "    for out_size, down_size in zip(layer_sizes, layer_sizes[1:]):\n",
    "      layer = self.make_layer(up_size, down_size, out_size)\n",
    "      self.layers.append(layer)\n",
    "      up_size = out_size\n",
    "    # Top layer only gets input from layer below, hence down_size=0.\n",
    "    top_layer = self.make_layer(up_size=layer_sizes[-2], down_size=0, out_size=layer_sizes[-1])\n",
    "    self.layers.append(top_layer)\n",
    "\n",
    "  def make_layer(self, up_size, down_size, out_size):\n",
    "    return FFLayer(up_size + down_size, out_size, lr=self.lr, max_obj=self.max_obj)\n",
    "\n",
    "  def init_layers_activity(self, input_shape):\n",
    "    # TODO: Could take labels for supervised learning\n",
    "    return [torch.zeros(*input_shape[:-1], l.out_features) for l in self.layers] + [torch.zeros(*input_shape[:-1], 0)]\n",
    "\n",
    "  def rollout(self, x, fns, **kwargs):\n",
    "    activity = [x] + self.init_layers_activity(input_shape=x.shape)\n",
    "\n",
    "    for _ in range(self.rollouts):\n",
    "      activity[1:-1] = [\n",
    "        fn(torch.cat((activity[i], activity[i+2]), dim=-1).detach(), **kwargs)\n",
    "        for i, fn in enumerate(fns) # TODO: Make this parallel\n",
    "      ]\n",
    "\n",
    "    return activity[1:-1]\n",
    "\n",
    "  def train(self, x, negative=False):\n",
    "    # This does not work:\n",
    "    # return self.rollout(x, [lambda y: layer.train(y, negative=negative) for layer in self.layers])\n",
    "    # However, this does?:\n",
    "    return self.rollout(x, [layer.train for layer in self.layers], negative=negative)\n",
    "\n",
    "  def train_pos(self, x):\n",
    "    return self.train(x, negative=False)\n",
    "\n",
    "  def train_neg(self, x):\n",
    "    return self.train(x, negative=True)\n",
    "  \n",
    "  def train_pos_neg(self, x_pos, x_neg):\n",
    "    pos_activity = self.train_pos(x_pos)\n",
    "    neg_activity = self.train_neg(x_neg)\n",
    "    return pos_activity, neg_activity\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.rollout(x, [layer.forward for layer in self.layers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentFFModel(input_size=28*28, layer_sizes=[400, 200, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, epochs):\n",
    "  for epoch in range(10):\n",
    "    for pos_data, neg_data in tqdm(train_data):\n",
    "      model.train_pos_neg(pos_data, neg_data)\n",
    "\n",
    "def test(model, test_data):\n",
    "  num_predictions = 0\n",
    "  num_correct = 0\n",
    "  for image, label in tqdm(test_data):\n",
    "    activity = model.forward(image)\n",
    "    mean_activities = torch.stack([(a**2).mean(dim=-1) for a in activity]).mean(dim=0)\n",
    "    preds = mean_activities.argmax(dim=-1)\n",
    "    correct = preds == label\n",
    "    num_predictions += len(preds)\n",
    "    num_correct += correct.sum()\n",
    "\n",
    "  accuracy = num_correct / num_predictions\n",
    "  return accuracy\n",
    "\n",
    "def make_mnist_train_data(overlay_label=False):\n",
    "  for image, label in mnist_train_data:\n",
    "    image = image.flatten(start_dim=1) # Flatten image\n",
    "    random_image = torch.randn_like(image)\n",
    "    if overlay_label:\n",
    "      one_hot_label = F.one_hot(label, num_classes=10)\n",
    "      image[:, :10] = one_hot_label\n",
    "    yield image, random_image\n",
    "\n",
    "def make_mnist_test_data(overlay_label=False):\n",
    "  for image, label in mnist_test_data:\n",
    "    image = image.flatten(start_dim=1) # Flatten image\n",
    "\n",
    "    image = image.expand(10, -1, -1).permute(1, 0, 2).clone() # [batch, 10, pixels]\n",
    "    image[:, :, :10] = F.one_hot(torch.arange(10))\n",
    "    \n",
    "    yield image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edecc9b393048f8b5ae567b87ebb8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1017)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, make_mnist_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87d3e1ffb4045eeafe4b79fd9671b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f194b1fdfc49929d45847a104a44ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8e7ed5bcea454aa051431be98bff4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a5e3d99ef84120ba1f7f295ad8f045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5cebb5d60c44f78e352aa9368ee841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35c585bdb4b478da519d3ab1c6511ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c296d1b03b440a19acd1a1f4ebe5468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be5b18e69d0441d961d283756d4c986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f19d2045bb43469d2aa08b5c24d1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896a41b8c89a466882de83d225160fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model, make_mnist_train_data(overlay_label=True), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463ed4d0d912440bade73eb06bed4c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0975)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, make_mnist_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
